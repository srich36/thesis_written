%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% chapter5.tex                                 %
% Contains formatting and content of chapter 5 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions and Recommendations for Future Work}

\section{Conclusions}
\noindent
Many particle swarm optimization methods
require significant time for algorithm execution and solution convergence. Furthermore, the probabilistic nature of stochastic methods necessitate aggregating multiple
algorithm runs for confidence in a quasi-optimal solution discovery. Improving these two major bottlenecks - long algorithm
runtimes and non-optimal swarm convergence - comprise the majority of this thesis' focus. 
To benchmark proposed improvements, the finite thrust arc problem was selected as an apt test case
for its computational complexity and non-trivial implementation. \newline

\noindent While the particle swarm optimization algorithm runtime is inherently constrained by the 
calculations it entails, optimizing memory transfer, caching, and computation can potentially speed up its
execution. To explore this possibility, three different implementations of the algorithm were developed:
single threaded MATLAB, single threaded C++, and parallel C++. Each implementation ran for the $\beta = 2$
transfer over a range of $P_{num}$ and $I_{num}$ values. Results clearly indicate that C++ implementations 
are over an order of magnitude faster, peaking at a multiple of 26 times single threaded, and 32 times faster
parallelized. It can be observed that parallelizing the implementation improves efficiency throughout the
beginning portion of the algorithm, but has overhead outweighing the benefits during the exploitation phase of
particle swarm optimization. Toggling parallelization during program execution may allow for peak
efficiency throughout. The results from this benchmarking demonstrate a significant improvement in 
algorithm performance. It is not unreasonable to consider real-time trajectory optimization maneuvers using 
similar C++ implementations in the future. \newline

\noindent The second problem this paper evaluates is increasing the probability of quasi-optimal solution 
discovery. As a stochastic algorithm, particle swarm optimization is prone to swarm stagnation, where the 
population prematurely converges on a non-optimal solution. This thesis' proposal of \textit{rehydration}
- the process of randomly resetting some of the population upon stagnation determination - is an attempt 
to rectify this behavior. \textit{Rehydration} results are tabulated for a series of the method's core parameters: $P_{r,\%}$,
$\delta_{Jcrit}$, $\eta_{iter}$, and compared against the average of 300 runs sans the reset technique. For each 
parameter combination, the \textit{rehydration} algorithm demonstrably improved the average solution discovered, peaking 
at an over 48\% efficiency increase.
This indicates that this method can improve the probability of quasi-optimal solution discovery, thus reducing the 
amount of algorithm runs necessary to find optimal transfer parameters. In combination with C++ implementations, this significantly 
improves the two bottlenecks preventing real-time trajectory optimization. \newline

\noindent While this paper focuses on the finite thrust arc problem as a test case, the proposed particle swarm optimization 
improvements extend beyond any one problem definition. Decreased runtime and increased reliability help
unlock particle swarm methods in scenarios requiring time-sensitive results. For the finite thrust arc problem, this may mean enabling 
on-board computers to calculate real-time transfer parameters autonomously. Yet, the benefits transcend this case,
extending to any problem domain utilizing particle swarm methods. \newline

\section{Recommendations For Future Work}

\noindent The core of this thesis proposes methods to improve the overall effectiveness of particle swarm 
optimization algorithms. While applied to the finite thrust transfer problem, their breadth is much further
reaching; these techniques can be used to optimize the solutions to a
wide variety of problems solved by computationally intensive particle swarm methods. Future work may be done in 
generalizing the C++ and \textit{rehydration} implementations and abstracting them for easy configuration and use 
in different problems. \newline

\noindent Additionally, this paper's exploration of concurrent programming as an algorithm optimization method
would benefit form a greater depth of research. As previously mentioned, developing an implementation with automatically
toggling parallelization based on swarm convergence state could help maintain peek efficiency throughout.
Other parallel implementations, namely graphical processing unit (GPU) programming, are also recommended to be considered. 
GPUs benefit from an immensely high thread count, enough for a thread per particle, but add increased overhead in copying
memory between host and device. An analysis of the tradeoffs between the increased multi-threaded efficiency and 
increased memory overhead is yet to be seen.

\newpage