%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% chapter3.tex                                 %
% Contains formatting and content of chapter 3 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Problem Implementation}
\section{Overview}
\noindent The finite thrust arc problem consists of 11 unknowns and requires two numerical integrations for each solution candidate within the
particle swarm. Additionally, it necessitates very small absolute and relative tolerances when integrated with variable step-size integrators. These
components serve to make this problem a suitable benchmark for the performance of different implementations of the particle swarm optimization algorithm. \newline

\noindent To maintain consistency between different implementation targets, the numerical integration algorithm, absolute and relative tolerance values,
and minimum step size constraints are held constant. All implementations employ a fifth order Runge-Kutta Dormand Prince variable step-size integrator
throughout both thrust arcs. The tolerances are defined as

\begin{equation}
AbsTol = 10^{-9} \quad \text{and} \quad RelTol = 10^{-9} 
\label{eq:tolerances}
\end{equation}

\noindent And the minimum step size set to the MATLAB default of

\begin{equation}
    h_{min} = 7.105427*10^{-15}
    \label{eq:min-step-size}
\end{equation}

\noindent Execution time is measured as wall-clock time and is computed from swarm initialization 
to algorithm completion. File operations are not included within this measurement. \newline

\noindent The problem is benchmarked using the $\beta = 2$ case with various swarm sizes and iteration numbers. 
Results from this benchmarking can be seen in Tables (\ref{tab:MATLAB-speedup}, \ref{tab:ST-speedup}, \ref{tab:OpenMP-speedup}). Unless otherwise 
specified, all data within this thesis is computed as the average of 30 algorithm executions held constant at the given parameters. 
All benchmarking is run without any \textit{rehydration} methods.
Numerical analysis is additionally performed on the $\beta=4,6,8 \text{ and } 10$ cases, though these solutions are not benchmarked for execution time.

\section{MATLAB}

\subsection{Integrator}

\noindent MATLAB implements a fifth-order Runge-Kutta Dormand-Prince variable step-size integrator with the native \code{ODE45} function. \code{ODE45}
defaults to a minimum step size of $h_{min}$ as given in Eq. (\ref{eq:min-step-size}). Additionally, \code{ODE45}
presents configuration options for both $AbsTol$ and $RelTol$, utilizing the larger of the two values.
Integrations for both thrust arcs are configured with the values given in Eq. (\ref{eq:tolerances}).

\subsection{Platform Specific Implementation Details}

\noindent As a stochastic algorithm, particle swarm optimization requires uniformly distributed random numbers to update particle velocities 
and explore the search space. MATLAB provides a \code{rand} function to generate uniformly distributed
psuedo-random numbers between $0$ and $1$. These numbers are used to generate the initial swarm and compute velocity accelerator coefficients as given by Eq. (\ref{eq:acceleratorCoefficients}).
Solutions are computed using the default 16 digits of precision. Execution time is measured using the standard MATLAB
functions \code{tic} and \code{toc}.


\subsection{Thrust Arcs}

\noindent Further analysis of the numerically determined optimal thrust arcs is computed within MATLAB.
The transfer is broken down into its three distinct components: the first thrust arc, the coasting arc, and the second thrust arc. 
A set of $r$ and $\theta$ values throughout these three durations are joined together for graphically modeling the given particle's transfer
solution. Results of these computations can be seen in Fig. (\ref{fig:Tarc-B2}). \newline

\subsection{Thrust Angles}

\noindent Analysis of the finite thrust transfer problem yields the optimal thrust-pointing-angle time history for a given transfer. 
From Eq. (\ref{delta_eq}) the thrust angle $\delta$ is computed for both the first and second thrust arcs. MATLAB is then used
to graphically model the thrust angle as a function of time for various quasi-optimal solutions. These results are seen in 
Fig. (\ref{fig:thrustAnglesB2}). \newline

\subsection{Rehydration}

\noindent Analysis of the rehydration technique focuses on determining the effect the parameters $\eta_{iter}$, $\delta_{Jcrit}$,
and $P_{r,\text{\%}}$ have on the solution. For each set of these parameters, the algorithm is ran 30 times and a $\bar{J}_{best}$
computed. This $\bar{J}_{best}$ is then compared against a $\bar{J}_{best}$ from the result of 300 executions of the algorithm without
the \textit{rehydration} method. Results from these comparisons can be seen in Tables 
(\ref{tab:rehydation-p25}, \ref{tab:rehydation-p33}, \ref{tab:rehydation-p50}).
All \textit{rehydration} cases are ran with $P_{num} = 100$ and $I_{num} = 1000$ for the $\beta=2$ case.



\section{C++ Single Threaded}

\noindent A C++ version of the main particle swarm optimization algorithm is implemented to benchmark execution time across targets.
C++ provides finer-grain memory management and allows for cache optimization and faster computations.
While the subject of these optimizations is beyond the scope of this thesis, they can be used to greatly speedup the execution time
of numerical algorithms. \newline

\noindent This research utilizes the C++ \code{Boost} libraries for numerical computations.
\code{Boost} implements the aforementioned cache and memory optimizations and is a de-facto standard
for high performance C++.

\subsection{Integrator}

\noindent \code{Boost} provides \code{odeint}, a library for solving ordinary differential equations. Within \code{odeint}
there exists a fifth-order Runge-Kutta Dormand-Prince variable
step-size integrator. This implements the same algorithm as \code{ODE45} and thus was chosen as the integrator for both finite
thrust arcs. The method exposes references to the system state which is updated and overwritten at each successive time step. Absolute
and relative tolerance options are provided, and are set to the values specified in Eq. (\ref{eq:tolerances}). \newline

\noindent By default \code{odeint} does not provide any minimum step size checks nor options to set $h_{min}$.
As such, a custom integration observer is implemented to compute and limit step size in accordance with Eq. (\ref{eq:min-step-size}). 
This observer evaluates solution time at successive steps in the integration process and computes their delta for 
$h_{min}$ regulation.

\subsection{Platform Specific Implementation Details}

\noindent To reduce computational complexity and integrate with \code{Boost} libraries, all 2-D arrays
are flattened to their one-dimensional counterparts. The corresponding one-dimensional index is computed as

\begin{equation}
    index = r(w+y)
    \label{eq:index-conversion}
\end{equation}

\noindent where $r$ is the zero-based two-dimension row number, $y$ the zero-based two-dimensional column number, and $w$ the two-dimensional array width. All flattened one-dimensional arrays are represented with double precision, dynamically allocated, contiguous blocks
of memory. \newline

\noindent
The C++ standard library provides a \code{rand} function for generating psuedo-random numbers.
To ensure randomness between successive executions, the \code{rand} function is seeded with the number
of seconds since the Epoch at the start of the program. This function returns an integer 
between $0$ and \code{\texttt{RAND\char`_MAX}}, where \code{\texttt{RAND\char`_MAX}} is architecture specific. 
For use in particle swarm optimization, this number is cast as a double
precision floating point number and bound between $0$ and $1$. This creates the uniformly distributed
random number generator required for the algorithm. \newline

\noindent Program execution time is measured using successive system calls to \code{gettimeofday}
at swarm initialization and algorithm completion. Each system call returns the number of seconds
and microseconds since the Epoch, enabling timing accuracy of up to $10^{-6}$ seconds.

\section{C++ Parallelization}
\noindent To reduce complexity and limit memory passing overhead, this thesis employs a shared-memory model of 
parallelization. In this model, memory is shared between all cores and threads on a singular node.
Standard C++ provides a POSIX compliant threading system to architecture parallel code with this structure. While this provides 
the lowest level of program management, its implementation is arduous and error prone. As such, the \code{OpenMP}
specification for creating parallelized programs is utilized. \newline

\noindent \code{OpenMP} provides a set of compiler directives for creating multi-threaded applications. Within parallelized
regions there must be no inter-thread memory dependency. Naturally, this allows \code{OpenMP} to parallelize particle
evaluation as seen in algorithm (\ref{alg:PPSOpsuedocode}). This research uses a simple  \code{parallel for}  directive to
run four concurrent threads within this parallel region.
\newpage